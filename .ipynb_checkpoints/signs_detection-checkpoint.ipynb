{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "os.chdir('C:/Users/SMXaS/PycharmProjects/signs_recognition')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Storing data and labels in the list\"\"\"\n",
    "data = []  # Empty list of data\n",
    "labels = []  # Empty list of labels\n",
    "# classes = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Locating working directory and printing it out\"\"\"\n",
    "file_path = os.getcwd()\n",
    "# print(file_path)\n",
    "# C:\\Users\\SMXaS\\PycharmProjects\\signs_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Looping through 43 classes\n",
    "Opening data - train file\n",
    "Declaring 'images' as faster way to open train file\n",
    "---------------------------------------------------\n",
    "Looping through settings of images\n",
    "Opening images\n",
    "Resizing the pictures\n",
    "Modifying the list with append for data and labels\n",
    "Raising the exception if there was any errors\n",
    "\"\"\"\n",
    "for pictures in range(43):\n",
    "    data_path = os.path.join(file_path, 'Data/Train', str(pictures))\n",
    "    images = os.listdir(data_path)\n",
    "    for setting in images:\n",
    "        try:\n",
    "            image = Image.open(data_path + '\\\\' + setting)\n",
    "            image = image.resize((30, 30))\n",
    "            image = np.array(image)\n",
    "            data.append(image)\n",
    "            labels.append(pictures)\n",
    "        except Exception as error:\n",
    "            print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Making data and labels list to be numpy arrays\"\"\"\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Printing out the shape of data and labels'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Printing out the shape of data and labels\"\"\"\n",
    "# print(data.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Preparing testing, training and setting up the parameters\"\"\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Converting classes to encode integer data\"\"\"\n",
    "y_train = to_categorical(y_train, 43)\n",
    "y_test = to_categorical(y_test, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Preparing the model\n",
    "Model has parameters from KERAS API\n",
    "Activation layers, filters, size, shape, rate which can be changed\n",
    "\"\"\"\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(43, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Compiling the model\"\"\"\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "981/981 [==============================] - 101s 103ms/step - loss: 1.9918 - accuracy: 0.5058 - val_loss: 0.6015 - val_accuracy: 0.8708\n",
      "Epoch 2/20\n",
      "981/981 [==============================] - 99s 100ms/step - loss: 0.7458 - accuracy: 0.7833 - val_loss: 0.2607 - val_accuracy: 0.9305\n",
      "Epoch 3/20\n",
      "981/981 [==============================] - 101s 103ms/step - loss: 0.5465 - accuracy: 0.8400 - val_loss: 0.2126 - val_accuracy: 0.9494\n",
      "Epoch 4/20\n",
      "981/981 [==============================] - 99s 101ms/step - loss: 0.4166 - accuracy: 0.8783 - val_loss: 0.1278 - val_accuracy: 0.9645\n",
      "Epoch 5/20\n",
      "981/981 [==============================] - 98s 100ms/step - loss: 0.3343 - accuracy: 0.9015 - val_loss: 0.1216 - val_accuracy: 0.9656\n",
      "Epoch 6/20\n",
      "981/981 [==============================] - 99s 101ms/step - loss: 0.3163 - accuracy: 0.9097 - val_loss: 0.0895 - val_accuracy: 0.9736\n",
      "Epoch 7/20\n",
      "981/981 [==============================] - 99s 101ms/step - loss: 0.2860 - accuracy: 0.9181 - val_loss: 0.1074 - val_accuracy: 0.9700\n",
      "Epoch 8/20\n",
      "981/981 [==============================] - 100s 102ms/step - loss: 0.2538 - accuracy: 0.9265 - val_loss: 0.0954 - val_accuracy: 0.9698\n",
      "Epoch 9/20\n",
      "981/981 [==============================] - 99s 101ms/step - loss: 0.2557 - accuracy: 0.9305 - val_loss: 0.0655 - val_accuracy: 0.9818\n",
      "Epoch 10/20\n",
      "981/981 [==============================] - 100s 102ms/step - loss: 0.2485 - accuracy: 0.9299 - val_loss: 0.0778 - val_accuracy: 0.9763\n",
      "Epoch 11/20\n",
      "981/981 [==============================] - 99s 101ms/step - loss: 0.2200 - accuracy: 0.9382 - val_loss: 0.0622 - val_accuracy: 0.9829\n",
      "Epoch 12/20\n",
      "981/981 [==============================] - 100s 102ms/step - loss: 0.2289 - accuracy: 0.9374 - val_loss: 0.0534 - val_accuracy: 0.9846\n",
      "Epoch 13/20\n",
      "981/981 [==============================] - 101s 103ms/step - loss: 0.2157 - accuracy: 0.9419 - val_loss: 0.0607 - val_accuracy: 0.9846\n",
      "Epoch 14/20\n",
      "981/981 [==============================] - 100s 101ms/step - loss: 0.2395 - accuracy: 0.9365 - val_loss: 0.0647 - val_accuracy: 0.9805\n",
      "Epoch 15/20\n",
      "981/981 [==============================] - 99s 101ms/step - loss: 0.2057 - accuracy: 0.9430 - val_loss: 0.0623 - val_accuracy: 0.9821\n",
      "Epoch 16/20\n",
      "981/981 [==============================] - 99s 101ms/step - loss: 0.2374 - accuracy: 0.9376 - val_loss: 0.0537 - val_accuracy: 0.9848\n",
      "Epoch 17/20\n",
      "981/981 [==============================] - 100s 102ms/step - loss: 0.2199 - accuracy: 0.9415 - val_loss: 0.0461 - val_accuracy: 0.9864\n",
      "Epoch 18/20\n",
      "981/981 [==============================] - 101s 103ms/step - loss: 0.2112 - accuracy: 0.9432 - val_loss: 0.0476 - val_accuracy: 0.9867\n",
      "Epoch 19/20\n",
      "981/981 [==============================] - 102s 104ms/step - loss: 0.2439 - accuracy: 0.9363 - val_loss: 0.0604 - val_accuracy: 0.9837\n",
      "Epoch 20/20\n",
      "981/981 [==============================] - 100s 102ms/step - loss: 0.1909 - accuracy: 0.9496 - val_loss: 0.0483 - val_accuracy: 0.9871\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Setting up the epochs and history of each compile\"\"\"\n",
    "epochs = 20\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=epochs, validation_data=(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
